{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Customer Churn\n",
    "\n",
    "In this Portfolio task you will work with some (fake but realistic) data on Mobile Customer Churn.  Churn is where\n",
    "a customer leaves the mobile provider.   The goal is to build a simple predictive model to predict churn from available features. \n",
    "\n",
    "The data was generated (by Hume Winzar at Macquarie) based on a real dataset provided by Optus.  The data is simulated but the column headings are the same. (Note that I'm not sure if all of the real relationships in this data are preserved so you need to be cautious in interpreting the results of your analysis here).  \n",
    "\n",
    "The data is provided in file `MobileCustomerChurn.csv` and column headings are defined in a file `MobileChurnDataDictionary.csv` (store these in the `files` folder in your project).\n",
    "\n",
    "Your high level goal in this notebook is to try to build and evaluate a __predictive model for churn__ - predict the value of the CHURN_IND field in the data from some of the other fields.  Note that the three `RECON` fields should not be used as they indicate whether the customer reconnected after having churned. \n",
    "\n",
    "__Note:__ you are not being evaluated on the _accuracy_ of the model but on the _process_ that you use to generate it.  You can use a simple model such as Logistic Regression for this task or try one of the more advanced methods covered in recent weeks.  Explore the data, build a model using a selection of features and then do some work on finding out which features provide the most accurate results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, cut_tree\n",
    "from scipy.spatial.distance import pdist \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, plot_confusion_matrix\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>ACCOUNT_TENURE</th>\n",
       "      <th>ACCT_CNT_SERVICES</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CFU</th>\n",
       "      <th>SERVICE_TENURE</th>\n",
       "      <th>PLAN_ACCESS_FEE</th>\n",
       "      <th>BYO_PLAN_STATUS</th>\n",
       "      <th>PLAN_TENURE</th>\n",
       "      <th>MONTHS_OF_CONTRACT_REMAINING</th>\n",
       "      <th>...</th>\n",
       "      <th>CONTRACT_STATUS</th>\n",
       "      <th>PREV_CONTRACT_DURATION</th>\n",
       "      <th>HANDSET_USED_BRAND</th>\n",
       "      <th>CHURN_IND</th>\n",
       "      <th>MONTHLY_SPEND</th>\n",
       "      <th>COUNTRY_METRO_REGION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>RECON_SMS_NEXT_MTH</th>\n",
       "      <th>RECON_TELE_NEXT_MTH</th>\n",
       "      <th>RECON_EMAIL_NEXT_MTH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>CONSUMER</td>\n",
       "      <td>46</td>\n",
       "      <td>54.54</td>\n",
       "      <td>NON BYO</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>OFF-CONTRACT</td>\n",
       "      <td>24</td>\n",
       "      <td>SAMSUNG</td>\n",
       "      <td>1</td>\n",
       "      <td>61.40</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>55.0</td>\n",
       "      <td>CONSUMER</td>\n",
       "      <td>59</td>\n",
       "      <td>54.54</td>\n",
       "      <td>NON BYO</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>OFF-CONTRACT</td>\n",
       "      <td>24</td>\n",
       "      <td>APPLE</td>\n",
       "      <td>1</td>\n",
       "      <td>54.54</td>\n",
       "      <td>METRO</td>\n",
       "      <td>NSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>CONSUMER</td>\n",
       "      <td>65</td>\n",
       "      <td>40.90</td>\n",
       "      <td>BYO</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>OFF-CONTRACT</td>\n",
       "      <td>12</td>\n",
       "      <td>APPLE</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>CONSUMER</td>\n",
       "      <td>31</td>\n",
       "      <td>31.81</td>\n",
       "      <td>NON BYO</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>OFF-CONTRACT</td>\n",
       "      <td>24</td>\n",
       "      <td>APPLE</td>\n",
       "      <td>1</td>\n",
       "      <td>6.48</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>VIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>CONSUMER</td>\n",
       "      <td>95</td>\n",
       "      <td>54.54</td>\n",
       "      <td>NON BYO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>OFF-CONTRACT</td>\n",
       "      <td>24</td>\n",
       "      <td>APPLE</td>\n",
       "      <td>1</td>\n",
       "      <td>100.22</td>\n",
       "      <td>METRO</td>\n",
       "      <td>NSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CUST_ID  ACCOUNT_TENURE  ACCT_CNT_SERVICES   AGE       CFU  \\\n",
       "INDEX                                                               \n",
       "1            1              46                  1  30.0  CONSUMER   \n",
       "2            2              60                  3  55.0  CONSUMER   \n",
       "3            5              65                  1  29.0  CONSUMER   \n",
       "4            6              31                  1  51.0  CONSUMER   \n",
       "5            8              95                  1  31.0  CONSUMER   \n",
       "\n",
       "       SERVICE_TENURE  PLAN_ACCESS_FEE BYO_PLAN_STATUS  PLAN_TENURE  \\\n",
       "INDEX                                                                 \n",
       "1                  46            54.54         NON BYO           15   \n",
       "2                  59            54.54         NON BYO            5   \n",
       "3                  65            40.90             BYO           15   \n",
       "4                  31            31.81         NON BYO           31   \n",
       "5                  95            54.54         NON BYO            0   \n",
       "\n",
       "       MONTHS_OF_CONTRACT_REMAINING  ...  CONTRACT_STATUS  \\\n",
       "INDEX                                ...                    \n",
       "1                                 0  ...     OFF-CONTRACT   \n",
       "2                                 0  ...     OFF-CONTRACT   \n",
       "3                                 0  ...     OFF-CONTRACT   \n",
       "4                                 0  ...     OFF-CONTRACT   \n",
       "5                                 0  ...     OFF-CONTRACT   \n",
       "\n",
       "      PREV_CONTRACT_DURATION  HANDSET_USED_BRAND CHURN_IND  MONTHLY_SPEND  \\\n",
       "INDEX                                                                       \n",
       "1                         24             SAMSUNG         1          61.40   \n",
       "2                         24               APPLE         1          54.54   \n",
       "3                         12               APPLE         1           2.50   \n",
       "4                         24               APPLE         1           6.48   \n",
       "5                         24               APPLE         1         100.22   \n",
       "\n",
       "       COUNTRY_METRO_REGION STATE RECON_SMS_NEXT_MTH  RECON_TELE_NEXT_MTH  \\\n",
       "INDEX                                                                       \n",
       "1                   COUNTRY    WA                NaN                  NaN   \n",
       "2                     METRO   NSW                NaN                  NaN   \n",
       "3                   COUNTRY    WA                NaN                  NaN   \n",
       "4                   COUNTRY   VIC                NaN                  NaN   \n",
       "5                     METRO   NSW                NaN                  NaN   \n",
       "\n",
       "       RECON_EMAIL_NEXT_MTH  \n",
       "INDEX                        \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  \n",
       "5                       NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn = pd.read_csv(\"files/MobileCustomerChurn.csv\", na_values=[\"NA\", \"#VALUE!\"], index_col='INDEX')\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Churn with Logistic Regression\n",
    "In order to predict the CHURN_IND, a Logistic Model will be appropriate. This is because CHURN_IND is a categorical variable (assuming 1 means the customer has churned, and 0 means the customer has not churned). \n",
    "This model will be produced following a series of steps:\n",
    "1. Cleaning the data and converting string/categorical data into numerical/binary data \n",
    "2. Splitting the data into training and testing sections\n",
    "3. Creating and training a Logistic Regression Model\n",
    "4. Evaluating the accuracy of the Logistic Regression Model\n",
    "5. Performing recursive feature elemination to see which features have the most/least effect on CHURN_IND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "The churn data is a mix of categorical and numerical data. In order to create the Logistic Regression model, we need the data to be all numerical. To solve this problem I will be using the method of \"One Hot Encoding\" (or pd.get_dummies) to convert the categorical data into numerical (binary) data. This will take each category in a column and split it across multiple columns (one for each category). These columns will then either contain 1 (if that row is equal to the category) or 0 (if that row is not equal to the category). For example the \"STATE\" column contains the values NSW,QLD,VIC..., this process will split this column up into a column called NSW, a column called QLD, a column called VIC and so on. If the row has the value NSW, the NSW column will contain a 1, and the other columns will contain a 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnAnalysis = churn.drop([\"CFU\", \"BYO_PLAN_STATUS\", \"CONTRACT_STATUS\", \"CUST_ID\", \"COUNTRY_METRO_REGION\", \"STATE\", \"RECON_TELE_NEXT_MTH\", \"RECON_EMAIL_NEXT_MTH\", \"RECON_SMS_NEXT_MTH\", \"HANDSET_USED_BRAND\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunrnAnalysis = churnAnalysis.dropna(how='any', inplace=True)\n",
    "churnAnalysis = churnAnalysis.join(pd.get_dummies(churn[\"HANDSET_USED_BRAND\"], dummy_na=False))\n",
    "churnAnalysis = churnAnalysis.join(pd.get_dummies(churn[\"CONTRACT_STATUS\"], dummy_na=False))\n",
    "churnAnalysis = churnAnalysis.join(pd.get_dummies(churn[\"CFU\"], dummy_na=False))\n",
    "churnAnalysis = churnAnalysis.join(pd.get_dummies(churn[\"BYO_PLAN_STATUS\"], dummy_na=False))\n",
    "churnAnalysis = churnAnalysis.join(pd.get_dummies(churn[\"COUNTRY_METRO_REGION\"], dummy_na=False))\n",
    "churnAnalysis = churnAnalysis.join(pd.get_dummies(churn[\"STATE\"], dummy_na=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "In order to properly train the model and then test to see if it can accurately predict churn, I will split the data up randomly. 80% of the data will make up the training data in which the model will learn what values influence the CHURN_IND value. The other 20% of the data will have the CHURN_IND column taken off, then run through the model which will attempt to predict was the CHURN_IND is. A comparison between the predicted CHURN_IND and the actual CHURN_IND of the testing data will give a good indication of how accurate the model is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36904, 34)\n",
      "(9226, 34)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(churnAnalysis, test_size=0.2, random_state = 100)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(['CHURN_IND'], axis=1)\n",
    "y_train = train['CHURN_IND']\n",
    "X_test = test.drop(['CHURN_IND'], axis=1)\n",
    "y_test = test['CHURN_IND']\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = lr.predict(X_train)\n",
    "test_preds = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: \n",
      "0.7234988077173207\n",
      "Test Accuracy: \n",
      "0.7233904183828311\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \")\n",
    "print(accuracy_score(y_train, train_preds))\n",
    "print(\"Test Accuracy: \")\n",
    "print(accuracy_score(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x207851d2e50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train Confusion Matrix: \")\n",
    "plot_confusion_matrix(lr, X_test, y_test, cmap=\"OrRd\", colorbar = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Summary\n",
    "As seen above the model had a train accuracy (the accuracy of the model when looking at its own data) of 0.7234. It also had a test accuracy (the accuracy of the model when looking at data it has not seen) of 0.7233. Additionally, the confusion matrix shows that the mode is quite good at predicting when CHURN_IND is 0, but not as good when predicting if CHURN_IND is 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "Our model contains a lot of different variables that will influence the accuracy of the output. In order to get a better idea of what features influence the model, I will create a recursive feature elimination model that will test the importance of each feature in the model. This will leave us with a ranking of the most important features in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(), n_features_to_select=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "rfe = RFE(estimator = lr, n_features_to_select = 1, step=1)\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features in order of importance to the model are as follows: \n",
      "[['ON-CONTRACT' 1]\n",
      " ['UNKNOWN' 2]\n",
      " ['BYO' 3]\n",
      " ['COUNTRY' 4]\n",
      " ['CONSUMER' 5]\n",
      " ['GOOGLE' 6]\n",
      " ['OFF-CONTRACT' 7]\n",
      " ['NO-CONTRACT' 8]\n",
      " ['NON BYO' 9]\n",
      " ['OTHER' 10]\n",
      " ['ACT' 11]\n",
      " ['WA' 12]\n",
      " ['QLD' 13]\n",
      " ['ACCT_CNT_SERVICES' 14]\n",
      " ['APPLE' 15]\n",
      " ['SAMSUNG' 16]\n",
      " ['MONTHS_OF_CONTRACT_REMAINING' 17]\n",
      " ['NSW' 18]\n",
      " ['AGE' 19]\n",
      " ['ACCOUNT_TENURE' 20]\n",
      " ['PREV_CONTRACT_DURATION' 21]\n",
      " ['SA' 22]\n",
      " ['MONTHLY_SPEND' 23]\n",
      " ['METRO' 24]\n",
      " ['LAST_FX_CONTRACT_DURATION' 25]\n",
      " ['TAS' 26]\n",
      " ['SMALL BUSINESS' 27]\n",
      " ['PLAN_TENURE' 28]\n",
      " ['SERVICE_TENURE' 29]\n",
      " ['VIC' 30]\n",
      " ['PLAN_ACCESS_FEE' 31]\n",
      " ['HUAWEI' 32]\n",
      " ['NT' 33]]\n"
     ]
    }
   ],
   "source": [
    "featureRanking = pd.DataFrame(X_train.columns, columns=['Features'])\n",
    "featureRanking = featureRanking.join(pd.DataFrame(rfe.ranking_, columns=['Rank']))\n",
    "featureRanking = featureRanking.sort_values(by=['Rank'])\n",
    "print(\"The features in order of importance to the model are as follows: \")\n",
    "print(str(featureRanking.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARY\n",
    "My model can predict whether a customer will churn or not with a 72% accuracy. The differnece in accuracy between the train and test sets for the model were negligable, this indicates that the model had low levels of over-fitting and will likely maintain its accuracy with new unseen data. \n",
    "\n",
    "However, as seen in the Confusion Matrix, the model could predict if CHURN_IND would be 0 with a much higher accuracy than it could predict if CHURN_IND would be 1. Although we are given little information about the data or what CHURN_IND means, if it were the case that CHURN_IND having a value of 1 meant that the customer would leave it is likely more useful for the model to be able to predict this with a high level of accuracy. Because of this, the model may not be useful practically as it has a low level of correct predictions when it predicts that CHURN_IND will be 1.\n",
    "\n",
    "Through the process of Recursive Feature Elimination, it can be seen that the most important features for predicting CHURN_IND are whether or not the customer was ON-CONTRACT, the type of phone the customer has (with UNKNOWN being the most relevant) and the variable of BYO. \n",
    "\n",
    "Having little information about the data, it is hard to make assumptions about the top predictors for churn. However, whether the customer was on or off contract would likely have a large effect on churn as customers coming off contract would be more likely to leave. Additionally, the type of phone being unknown may be indicitive of sales for Telstra not having enough information about the customer and therefore not being able to predict their needs. Those reasons are purely speculative but may offer some insight into the rankings of features for the Logistic Regression model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
